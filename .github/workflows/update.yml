name: Update Pet Data
on:
  schedule:
    - cron: '0 0 * * 0'  # Läuft jeden Sonntag um 00:00 UTC
  workflow_dispatch:      # Ermöglicht manuellen Start

jobs:
  scrape_and_update:
    runs-on: ubuntu-latest
    
    steps:
    # 1. Repository auschecken
    - uses: actions/checkout@v3
    
    # 2. Python einrichten
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    # 3. Abhängigkeiten installieren
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install beautifulsoup4 requests
    
    # 4. Skripte ausführen
    - name: Run scraping
      run: |
        python petopia_scraper.py
        python json_to_lua.py
    
    # 5. Änderungen hochladen
    - name: Commit and push
      run: |
        git config --global user.name "GitHub Actions"
        git config --global user.email "actions@github.com"
        git add .
        git commit -m "Automatisches Daten-Update $(date +'%Y-%m-%d')" || echo "Keine Änderungen"
        git push